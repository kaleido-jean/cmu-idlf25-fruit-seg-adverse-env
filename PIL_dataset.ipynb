{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Install dependencies\n",
        "# ================================\n",
        "!pip install -q roboflow diffusers transformers accelerate safetensors pillow matplotlib numpy\n",
        "\n",
        "# ================================\n",
        "# Imports\n",
        "# ================================\n",
        "from roboflow import Roboflow\n",
        "import random\n",
        "import os, torch, random, shutil\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance, ImageFilter\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "from diffusers.utils import logging\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "71lgVxwsnf6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2250349d-a29c-4993-a8d3-a0aa379d5e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = Roboflow(api_key=\"7TI8mHPqsyInAEUtwLsa\")\n",
        "project = rf.workspace(\"en-zbzva\").project(\"all-pepper-datasets-q5opc\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"voc\")\n",
        "\n",
        "dataset_dir = dataset.location\n",
        "\n",
        "train_dir = os.path.join(dataset_dir, \"train\")\n",
        "val_dir   = os.path.join(dataset_dir, \"valid\")\n",
        "test_dir  = os.path.join(dataset_dir, \"test\")\n",
        "\n",
        "train_imgs = [os.path.join(train_dir, f) for f in os.listdir(train_dir) if f.endswith(\".jpg\")]\n",
        "val_imgs   = [os.path.join(val_dir,   f) for f in os.listdir(val_dir)   if f.endswith(\".jpg\")]\n",
        "test_imgs  = [os.path.join(test_dir,  f) for f in os.listdir(test_dir)  if f.endswith(\".jpg\")]\n",
        "\n",
        "train_dir_lbl = [os.path.join(train_dir, f) for f in os.listdir(train_dir) if f.endswith(\".xml\")]\n",
        "val_dir_lbl   = [os.path.join(val_dir,   f) for f in os.listdir(val_dir)   if f.endswith(\".xml\")]\n",
        "test_dir_lbl  = [os.path.join(test_dir,  f) for f in os.listdir(test_dir)  if f.endswith(\".xml\")]\n",
        "\n",
        "\n",
        "print(\"Train images:\", len(train_imgs))\n",
        "print(\"Valid images:\", len(val_imgs))\n",
        "print(\"Test images:\", len(test_imgs))\n",
        "print(\"Train labels:\", len(train_dir_lbl))\n",
        "print(\"Valid labels:\", len(val_dir_lbl))\n",
        "print(\"Test labels:\", len(test_dir_lbl))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L8rWfQaWdJH",
        "outputId": "bca907c8-6f2d-44ea-a748-64f1c455312c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Train images: 1489\n",
            "Valid images: 427\n",
            "Test images: 211\n",
            "Train labels: 1489\n",
            "Valid labels: 427\n",
            "Test labels: 211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # ================================\n",
        "# # Load Roboflow dataset\n",
        "# # ================================\n",
        "# rf = Roboflow(api_key=\"7TI8mHPqsyInAEUtwLsa\")\n",
        "# project = rf.workspace(\"en-zbzva\").project(\"all-pepper-datasets-q5opc\")\n",
        "# version = project.version(1)\n",
        "# dataset = version.download(\"yolov9\")\n",
        "\n",
        "# dataset_dir = dataset.location\n",
        "# train_dir_img = os.path.join(dataset_dir, \"train\", \"images\")\n",
        "# val_dir_img   = os.path.join(dataset_dir, \"valid\", \"images\")\n",
        "# test_dir_img  = os.path.join(dataset_dir, \"test\",  \"images\")\n",
        "\n",
        "# train_dir_lbl = os.path.join(dataset_dir, \"train\", \"labels\")\n",
        "# val_dir_lbl   = os.path.join(dataset_dir, \"valid\", \"labels\")\n",
        "# test_dir_lbl  = os.path.join(dataset_dir, \"test\",  \"labels\")\n",
        "\n",
        "# print(\"Roboflow source dataset:\")\n",
        "# print(\" Train images:\", len(os.listdir(train_dir_img)))\n",
        "# print(\" Valid images:\", len(os.listdir(val_dir_img)))\n",
        "# print(\" Test  images:\", len(os.listdir(test_dir_img)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0GwBCQ0nnP7",
        "outputId": "508734d3-bc52-440c-d4e4-2b6a47e4b723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in All-Pepper-Datasets-1 to yolov9:: 100%|██████████| 110813/110813 [00:07<00:00, 15121.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to All-Pepper-Datasets-1 in yolov9:: 100%|██████████| 4266/4266 [00:00<00:00, 6704.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Roboflow source dataset:\n",
            " Train images: 1489\n",
            " Valid images: 427\n",
            " Test  images: 211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # ============================================\n",
        "# # 3. Classical augmentation functions\n",
        "# #    (NO geometry change → labels stay valid)\n",
        "# # ============================================\n",
        "\n",
        "# def apply_weak_light(img):\n",
        "#     \"\"\"Simulate weak, cloudy light. No resize, no geometry change.\"\"\"\n",
        "#     img = ImageEnhance.Brightness(img).enhance(0.55)\n",
        "#     img = ImageEnhance.Contrast(img).enhance(0.75)\n",
        "#     img = ImageEnhance.Color(img).enhance(0.80)\n",
        "#     return img\n",
        "\n",
        "# def apply_foggy_base(img):\n",
        "#     \"\"\"Slightly soften contrast/colors before fog overlay.\"\"\"\n",
        "#     img = ImageEnhance.Brightness(img).enhance(1.05)\n",
        "#     img = ImageEnhance.Contrast(img).enhance(0.65)\n",
        "#     img = ImageEnhance.Color(img).enhance(0.75)\n",
        "#     return img\n",
        "\n",
        "# def add_fog_overlay(img, intensity=0.55):\n",
        "#     \"\"\"\n",
        "#     Add a fog overlay using alpha-composited white veil.\n",
        "#     No resizing, no cropping.\n",
        "#     \"\"\"\n",
        "#     w, h = img.size\n",
        "#     fog = Image.new(\"RGBA\", img.size, (255, 255, 255, 0))\n",
        "#     fog_px = fog.load()\n",
        "\n",
        "#     for i in range(w):\n",
        "#         for j in range(h):\n",
        "#             # Denser fog towards top of image (can tweak)\n",
        "#             alpha = int(255 * intensity * np.exp(-((j / h) * 1.5)))\n",
        "#             fog_px[i, j] = (255, 255, 255, alpha)\n",
        "\n",
        "#     fog = fog.filter(ImageFilter.GaussianBlur(10))\n",
        "#     return Image.alpha_composite(img.convert(\"RGBA\"), fog).convert(\"RGB\")\n",
        "\n",
        "# def augment_classical(img_path, out_path, mode):\n",
        "#     \"\"\"\n",
        "#     mode: 'weak' or 'foggy'\n",
        "#     img_path: source image path\n",
        "#     out_path: destination image path\n",
        "#     \"\"\"\n",
        "#     img = Image.open(img_path).convert(\"RGB\")  # keep original resolution\n",
        "\n",
        "#     if mode == \"weak\":\n",
        "#         img = apply_weak_light(img)\n",
        "#     elif mode == \"foggy\":\n",
        "#         img = apply_foggy_base(img)\n",
        "#         img = add_fog_overlay(img, intensity=0.55)\n",
        "#     else:\n",
        "#         raise ValueError(\"mode must be 'weak' or 'foggy'\")\n",
        "\n",
        "#     img.save(out_path, quality=95)\n"
      ],
      "metadata": {
        "id": "-TbDZuaznqKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ============================================\n",
        "# RANDOMIZED Weak-Light\n",
        "# ============================================\n",
        "def apply_weak_light(img):\n",
        "    \"\"\"Randomized weak-light augmentation (safe for labels).\"\"\"\n",
        "\n",
        "    # Random ranges (feel free to tweak)\n",
        "    brightness = random.uniform(0.45, 0.75)\n",
        "    contrast   = random.uniform(0.60, 0.90)\n",
        "    color      = random.uniform(0.70, 0.90)\n",
        "    sharpness  = random.uniform(0.70, 1.00)\n",
        "\n",
        "    img = ImageEnhance.Brightness(img).enhance(brightness)\n",
        "    img = ImageEnhance.Contrast(img).enhance(contrast)\n",
        "    img = ImageEnhance.Color(img).enhance(color)\n",
        "    img = ImageEnhance.Sharpness(img).enhance(sharpness)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# RANDOMIZED Foggy base (before fog overlay)\n",
        "# ============================================\n",
        "def apply_foggy_base(img):\n",
        "    \"\"\"Randomized fog-prep adjustment.\"\"\"\n",
        "    brightness = random.uniform(1.00, 1.15)\n",
        "    contrast   = random.uniform(0.55, 0.75)\n",
        "    color      = random.uniform(0.65, 0.80)\n",
        "\n",
        "    img = ImageEnhance.Brightness(img).enhance(brightness)\n",
        "    img = ImageEnhance.Contrast(img).enhance(contrast)\n",
        "    img = ImageEnhance.Color(img).enhance(color)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# RANDOMIZED Fog Overlay\n",
        "# ============================================\n",
        "def add_fog_overlay(img, intensity=None):\n",
        "    \"\"\"\n",
        "    Add fog overlay with random intensity and random blur.\n",
        "    intensity: if None, choose random.\n",
        "    \"\"\"\n",
        "    if intensity is None:\n",
        "        intensity = random.uniform(0.35, 0.70)   # fog thickness\n",
        "\n",
        "    blur_amt = random.uniform(5, 12)            # background fog blur\n",
        "    grad_exp = random.uniform(1.0, 1.8)         # fog depth profile\n",
        "\n",
        "    w, h = img.size\n",
        "    fog = Image.new(\"RGBA\", (w, h), (255,255,255,0))\n",
        "    px = fog.load()\n",
        "\n",
        "    for i in range(w):\n",
        "        for j in range(h):\n",
        "            # randomized gradient exponent\n",
        "            alpha = int(255 * intensity * np.exp(-((j/h) * grad_exp)))\n",
        "            px[i, j] = (255,255,255,alpha)\n",
        "\n",
        "    fog = fog.filter(ImageFilter.GaussianBlur(blur_amt))\n",
        "    return Image.alpha_composite(img.convert(\"RGBA\"), fog).convert(\"RGB\")\n",
        "\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# FINAL augmentation function\n",
        "# ============================================\n",
        "def augment_classical(img_path, out_path, mode):\n",
        "    \"\"\"\n",
        "    mode: 'weak' or 'foggy'\n",
        "    Randomized classical augmentation.\n",
        "    \"\"\"\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "    if mode == \"weak\":\n",
        "        img = apply_weak_light(img)\n",
        "\n",
        "    elif mode == \"foggy\":\n",
        "        img = apply_foggy_base(img)\n",
        "        img = add_fog_overlay(img)   # fog is randomized each time\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"mode must be 'weak' or 'foggy'\")\n",
        "\n",
        "    img.save(out_path, quality=95)\n"
      ],
      "metadata": {
        "id": "H_X9ndhkYRZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 4. Output dataset roots in Google Drive\n",
        "# ============================================\n",
        "root_weak  = \"/content/drive/MyDrive/pepper_weaklight\"\n",
        "root_foggy = \"/content/drive/MyDrive/pepper_foggy\"\n",
        "\n",
        "for root in [root_weak, root_foggy]:\n",
        "    for split in [\"train\", \"valid\", \"test_roboflow\"]:\n",
        "        os.makedirs(os.path.join(root, split, \"images\"), exist_ok=True)\n",
        "        os.makedirs(os.path.join(root, split, \"labels\"), exist_ok=True)\n",
        "\n",
        "print(\"Output roots:\")\n",
        "print(\" Weak-light:\", root_weak)\n",
        "print(\" Foggy     :\", root_foggy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvRK2RSPP9GJ",
        "outputId": "5fcaf616-e478-4920-d465-ca422dedfb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output roots:\n",
            " Weak-light: /content/drive/MyDrive/pepper_weaklight\n",
            " Foggy     : /content/drive/MyDrive/pepper_foggy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 5. Split processor with SKIP logic\n",
        "# ============================================\n",
        "def process_split_classical(src_img_dir, dst_root, mode, split_name):\n",
        "    \"\"\"\n",
        "    src_img_dir: original Roboflow images (train/valid/test)\n",
        "    dst_root: root_weak or root_foggy\n",
        "    mode: 'weak' or 'foggy'\n",
        "    split_name: 'train' / 'valid' / 'test_roboflow'\n",
        "    \"\"\"\n",
        "    dst_img_dir = os.path.join(dst_root, split_name, \"images\")\n",
        "    os.makedirs(dst_img_dir, exist_ok=True)\n",
        "\n",
        "    src_files = sorted([\n",
        "        f for f in os.listdir(src_img_dir)\n",
        "        if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))\n",
        "    ])\n",
        "    dst_files = sorted([\n",
        "        f for f in os.listdir(dst_img_dir)\n",
        "        if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))\n",
        "    ])\n",
        "\n",
        "    if len(dst_files) >= len(src_files) and len(src_files) > 0:\n",
        "        print(f\"[{mode}] {split_name}: {len(dst_files)}/{len(src_files)} images already exist → SKIP\")\n",
        "        return\n",
        "\n",
        "    print(f\"[{mode}] {split_name}: generating {len(src_files)} images...\")\n",
        "\n",
        "    for fname in src_files:\n",
        "        in_path  = os.path.join(src_img_dir, fname)\n",
        "        out_path = os.path.join(dst_img_dir, fname)\n",
        "\n",
        "        if os.path.exists(out_path):\n",
        "            continue\n",
        "\n",
        "        augment_classical(in_path, out_path, mode)"
      ],
      "metadata": {
        "id": "cc5s-SRdzPdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ============================================\n",
        "# # 5. Split processor with SKIP logic\n",
        "# # ============================================\n",
        "# def process_split_classical(src_img_dir, dst_root, mode, split_name):\n",
        "#     \"\"\"\n",
        "#     src_img_dir: original Roboflow images (train/valid/test)\n",
        "#     dst_root: root_weak or root_foggy\n",
        "#     mode: 'weak' or 'foggy'\n",
        "#     split_name: 'train' / 'valid' / 'test_roboflow'\n",
        "#     \"\"\"\n",
        "#     dst_img_dir = os.path.join(dst_root, split_name, \"images\")\n",
        "#     os.makedirs(dst_img_dir, exist_ok=True)\n",
        "\n",
        "#     src_files = sorted([\n",
        "#         f for f in os.listdir(src_img_dir)\n",
        "#         if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))\n",
        "#     ])\n",
        "#     dst_files = sorted([\n",
        "#         f for f in os.listdir(dst_img_dir)\n",
        "#         if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))\n",
        "#     ])\n",
        "\n",
        "#     if len(dst_files) >= len(src_files) and len(src_files) > 0:\n",
        "#         print(f\"[{mode}] {split_name}: {len(dst_files)}/{len(src_files)} images already exist → SKIP\")\n",
        "#         return\n",
        "\n",
        "#     print(f\"[{mode}] {split_name}: generating {len(src_files)} images...\")\n",
        "\n",
        "#     for fname in src_files:\n",
        "#         in_path  = os.path.join(src_img_dir, fname)\n",
        "#         out_path = os.path.join(dst_img_dir, fname)\n",
        "\n",
        "#         if os.path.exists(out_path):\n",
        "#             continue\n",
        "\n",
        "#         augment_classical(in_path, out_path, mode)"
      ],
      "metadata": {
        "id": "IhueVD0ValkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 6. Generate Weak-Light dataset (classical)\n",
        "# ============================================\n",
        "process_split_classical(train_dir, root_weak,  \"weak\",  \"train\")\n",
        "process_split_classical(val_dir,   root_weak,  \"weak\",  \"valid\")\n",
        "process_split_classical(test_dir,  root_weak,  \"weak\",  \"test_roboflow\")\n",
        "\n",
        "# ============================================\n",
        "# 7. Generate Foggy dataset (classical)\n",
        "# ============================================\n",
        "process_split_classical(train_dir, root_foggy, \"foggy\", \"train\")\n",
        "process_split_classical(val_dir,   root_foggy, \"foggy\", \"valid\")\n",
        "process_split_classical(test_dir,  root_foggy, \"foggy\", \"test_roboflow\")\n",
        "\n",
        "print(\"Finished generating weak-light & foggy datasets!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8XkwNbda8GC",
        "outputId": "e5116d27-3606-43e5-f74b-896ad1aaa55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[weak] train: generating 1489 images...\n",
            "[weak] valid: generating 427 images...\n",
            "[weak] test_roboflow: generating 211 images...\n",
            "[foggy] train: generating 1489 images...\n",
            "[foggy] valid: generating 427 images...\n",
            "[foggy] test_roboflow: generating 211 images...\n",
            "Finished generating weak-light & foggy datasets!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # ============================================\n",
        "# # 6. Generate Weak-Light dataset (classical)\n",
        "# # ============================================\n",
        "# process_split_classical(train_imgs, root_weak,  \"weak\",  \"train\")\n",
        "# process_split_classical(val_imgs,   root_weak,  \"weak\",  \"valid\")\n",
        "# process_split_classical(test_imgs,  root_weak,  \"weak\",  \"test_roboflow\")\n",
        "\n",
        "# # ============================================\n",
        "# # 7. Generate Foggy dataset (classical)\n",
        "# # ============================================\n",
        "# process_split_classical(train_imgs, root_foggy, \"foggy\", \"train\")\n",
        "# process_split_classical(val_imgs,   root_foggy, \"foggy\", \"valid\")\n",
        "# process_split_classical(test_imgs,  root_foggy, \"foggy\", \"test_roboflow\")\n",
        "\n",
        "# print(\"Finished generating weak-light & foggy datasets!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "OQ4SgHIxzQ3A",
        "outputId": "1112f301-9670-4fc5-dc36-85242343f29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "listdir: path should be string, bytes, os.PathLike, integer or None, not list",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3192632895.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 6. Generate Weak-Light dataset (classical)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ============================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprocess_split_classical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_weak\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"weak\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprocess_split_classical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_imgs\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mroot_weak\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"weak\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprocess_split_classical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_imgs\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mroot_weak\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"weak\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"test_roboflow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4050577490.py\u001b[0m in \u001b[0;36mprocess_split_classical\u001b[0;34m(src_img_dir, dst_root, mode, split_name)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     src_files = sorted([\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_img_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".jpeg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     ])\n",
            "\u001b[0;31mTypeError\u001b[0m: listdir: path should be string, bytes, os.PathLike, integer or None, not list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # ============================================\n",
        "# # 8. Copy labels (labels are reusable!)\n",
        "# # ============================================\n",
        "# def copy_labels(src_lbl_dir, dst_root, split_name):\n",
        "#     dst_lbl_dir = os.path.join(dst_root, split_name, \"labels\")\n",
        "#     os.makedirs(dst_lbl_dir, exist_ok=True)\n",
        "\n",
        "#     src_files = [f for f in os.listdir(src_lbl_dir) if f.endswith(\".txt\")]\n",
        "#     dst_files = [f for f in os.listdir(dst_lbl_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "#     if len(dst_files) >= len(src_files) and len(src_files) > 0:\n",
        "#         print(f\"[LABELS] {os.path.basename(dst_root)} {split_name}: already copied → SKIP\")\n",
        "#         return\n",
        "\n",
        "#     print(f\"[LABELS] {os.path.basename(dst_root)} {split_name}: copying {len(src_files)} labels...\")\n",
        "#     for f in src_files:\n",
        "#         shutil.copy(\n",
        "#             os.path.join(src_lbl_dir, f),\n",
        "#             os.path.join(dst_lbl_dir, f)\n",
        "#         )\n",
        "\n",
        "# # Weak-light labels\n",
        "# copy_labels(train_dir_lbl, root_weak,  \"train\")\n",
        "# copy_labels(val_dir_lbl,   root_weak,  \"valid\")\n",
        "# copy_labels(test_dir_lbl,  root_weak,  \"test_roboflow\")\n",
        "\n",
        "# # Foggy labels\n",
        "# copy_labels(train_dir_lbl, root_foggy, \"train\")\n",
        "# copy_labels(val_dir_lbl,   root_foggy, \"valid\")\n",
        "# copy_labels(test_dir_lbl,  root_foggy, \"test_roboflow\")\n",
        "\n",
        "# print(\" All labels copied.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "TgK1x1igzZKf",
        "outputId": "0b5a08a5-745c-478c-8f12-947c23cd962f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "listdir: path should be string, bytes, os.PathLike, integer or None, not list",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-388858282.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Weak-light labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mcopy_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir_lbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_weak\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mcopy_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dir_lbl\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mroot_weak\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcopy_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir_lbl\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mroot_weak\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m\"test_roboflow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-388858282.py\u001b[0m in \u001b[0;36mcopy_labels\u001b[0;34m(src_lbl_dir, dst_root, split_name)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_lbl_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msrc_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_lbl_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdst_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_lbl_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: listdir: path should be string, bytes, os.PathLike, integer or None, not list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 8. Copy labels (labels are reusable!)\n",
        "# ============================================\n",
        "def copy_labels(src_lbl_list, dst_root, split_name):\n",
        "    \"\"\"\n",
        "    src_lbl_list: a list of full .xml label paths\n",
        "    dst_root:     root_weak or root_foggy\n",
        "    split_name:   train / valid / test_roboflow\n",
        "    \"\"\"\n",
        "    dst_lbl_dir = os.path.join(dst_root, split_name, \"labels\")\n",
        "    os.makedirs(dst_lbl_dir, exist_ok=True)\n",
        "\n",
        "    # Extract just the filenames that should exist in dst\n",
        "    src_files = [os.path.basename(f) for f in src_lbl_list]\n",
        "    dst_files = [f for f in os.listdir(dst_lbl_dir) if f.endswith(\".xml\")]\n",
        "\n",
        "    # Skip if already copied\n",
        "    if len(dst_files) >= len(src_files) and len(src_files) > 0:\n",
        "        print(f\"[LABELS] {os.path.basename(dst_root)} {split_name}: already copied → SKIP\")\n",
        "        return\n",
        "\n",
        "    print(f\"[LABELS] {os.path.basename(dst_root)} {split_name}: copying {len(src_files)} labels...\")\n",
        "\n",
        "    # Copy each xml\n",
        "    for lbl_path in src_lbl_list:\n",
        "        fname = os.path.basename(lbl_path)\n",
        "        shutil.copy(lbl_path, os.path.join(dst_lbl_dir, fname))\n",
        "\n",
        "\n",
        "# Weak-light labels\n",
        "copy_labels(train_dir_lbl, root_weak,  \"train\")\n",
        "copy_labels(val_dir_lbl,   root_weak,  \"valid\")\n",
        "copy_labels(test_dir_lbl,  root_weak,  \"test_roboflow\")\n",
        "\n",
        "# Foggy labels\n",
        "copy_labels(train_dir_lbl, root_foggy, \"train\")\n",
        "copy_labels(val_dir_lbl,   root_foggy, \"valid\")\n",
        "copy_labels(test_dir_lbl,  root_foggy, \"test_roboflow\")\n",
        "\n",
        "print(\" All labels copied.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2acPB6Ag-Lt",
        "outputId": "46bffdba-3f0e-4f37-c23f-d1426ed68be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LABELS] pepper_weaklight train: copying 1489 labels...\n",
            "[LABELS] pepper_weaklight valid: copying 427 labels...\n",
            "[LABELS] pepper_weaklight test_roboflow: copying 211 labels...\n",
            "[LABELS] pepper_foggy train: copying 1489 labels...\n",
            "[LABELS] pepper_foggy valid: copying 427 labels...\n",
            "[LABELS] pepper_foggy test_roboflow: copying 211 labels...\n",
            " All labels copied.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # ============================================\n",
        "# # 8. Copy YOLO labels (labels are reusable!)\n",
        "# # ============================================\n",
        "# def copy_labels(src_lbl_dir, dst_root, split_name):\n",
        "#     dst_lbl_dir = os.path.join(dst_root, split_name, \"labels\")\n",
        "#     os.makedirs(dst_lbl_dir, exist_ok=True)\n",
        "\n",
        "#     src_files = [f for f in os.listdir(src_lbl_dir) if f.endswith(\".txt\")]\n",
        "#     dst_files = [f for f in os.listdir(dst_lbl_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "#     if len(dst_files) >= len(src_files) and len(src_files) > 0:\n",
        "#         print(f\"[LABELS] {os.path.basename(dst_root)} {split_name}: already copied → SKIP\")\n",
        "#         return\n",
        "\n",
        "#     print(f\"[LABELS] {os.path.basename(dst_root)} {split_name}: copying {len(src_files)} labels...\")\n",
        "#     for f in src_files:\n",
        "#         shutil.copy(\n",
        "#             os.path.join(src_lbl_dir, f),\n",
        "#             os.path.join(dst_lbl_dir, f)\n",
        "#         )\n",
        "\n",
        "# # Weak-light labels\n",
        "# copy_labels(train_dir_lbl, root_weak,  \"train\")\n",
        "# copy_labels(val_dir_lbl,   root_weak,  \"valid\")\n",
        "# copy_labels(test_dir_lbl,  root_weak,  \"test_roboflow\")\n",
        "\n",
        "# # Foggy labels\n",
        "# copy_labels(train_dir_lbl, root_foggy, \"train\")\n",
        "# copy_labels(val_dir_lbl,   root_foggy, \"valid\")\n",
        "# copy_labels(test_dir_lbl,  root_foggy, \"test_roboflow\")\n",
        "\n",
        "# print(\" All labels copied.\")"
      ],
      "metadata": {
        "id": "CkHD53iwbOOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_split_txt(img_dir, save_path):\n",
        "    \"\"\"\n",
        "    img_dir: folder containing .jpg images\n",
        "    save_path: full path to output txt file\n",
        "    \"\"\"\n",
        "    # Collect JPG filenames\n",
        "    names = sorted([f for f in os.listdir(img_dir) if f.lower().endswith(\".jpg\")])\n",
        "\n",
        "    # Remove \".jpg\" extension\n",
        "    names_no_ext = [os.path.splitext(f)[0] for f in names]\n",
        "\n",
        "    # Save to txt file\n",
        "    with open(save_path, \"w\") as f:\n",
        "        for n in names_no_ext:\n",
        "            f.write(n + \"\\n\")\n",
        "\n",
        "    print(f\"✓ Saved {len(names_no_ext)} entries → {save_path}\")"
      ],
      "metadata": {
        "id": "lm6vX_lMiYrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a folder inside MyDrive for output\n",
        "txt_out_dir = \"/content/drive/MyDrive/pepper_lists\"\n",
        "os.makedirs(txt_out_dir, exist_ok=True)\n",
        "\n",
        "# Full save paths\n",
        "train_txt = os.path.join(txt_out_dir, \"train.txt\")\n",
        "val_txt   = os.path.join(txt_out_dir, \"val.txt\")\n",
        "test_txt  = os.path.join(txt_out_dir, \"test.txt\")\n",
        "\n",
        "# Generate the txt files\n",
        "make_split_txt(train_dir, train_txt)\n",
        "make_split_txt(val_dir,   val_txt)\n",
        "make_split_txt(test_dir,  test_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7OYXvwmicA0",
        "outputId": "4ad50190-2811-41b6-c6f3-bd371d25a6e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Saved 1489 entries → /content/drive/MyDrive/pepper_lists/train.txt\n",
            "✓ Saved 427 entries → /content/drive/MyDrive/pepper_lists/val.txt\n",
            "✓ Saved 211 entries → /content/drive/MyDrive/pepper_lists/test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# DataLoaders\n",
        "# ================================\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "class PepperDataset(Dataset):\n",
        "    def __init__(self, img_dir):\n",
        "        self.img_dir = img_dir\n",
        "        self.files = sorted([f for f in os.listdir(img_dir) if f.lower().endswith((\".jpg\",\".png\",\".jpeg\"))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.files[idx]\n",
        "        img = Image.open(os.path.join(self.img_dir, fname)).convert(\"RGB\")\n",
        "        return transform(img), fname\n",
        "\n",
        "def make_loaders(root, batch=16):\n",
        "    return (\n",
        "        DataLoader(PepperDataset(os.path.join(root,\"train\",\"images\")), batch_size=batch, shuffle=True),\n",
        "        DataLoader(PepperDataset(os.path.join(root,\"valid\",\"images\")), batch_size=batch, shuffle=False),\n",
        "        DataLoader(PepperDataset(os.path.join(root,\"test_roboflow\",\"images\")),  batch_size=batch, shuffle=False),\n",
        "    )\n",
        "\n",
        "foggy_train_loader, foggy_val_loader, foggy_test_loader = make_loaders(root_foggy)\n",
        "weak_train_loader,  weak_val_loader,  weak_test_loader  = make_loaders(root_weak)\n",
        "\n",
        "print(\"All dataloaders ready!\")\n"
      ],
      "metadata": {
        "id": "xQEPNptwSWDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb57d1d0-59c5-454d-fe3a-eafe26c53083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dataloaders ready!\n"
          ]
        }
      ]
    }
  ]
}